# Origin cluster credentials (use "host + port" OR "secure-connect-bundle" but not both)
spark.origin.host                                 localhost
spark.origin.port                                 9042
#spark.origin.scb                                 file:///aaa/bbb/secure-connect-enterprise.zip
spark.origin.username                             some-username
spark.origin.password                             some-secret-password

# Read & Write rate-limits(rows/second). Higher value will improve performance and put more load on cluster
spark.readRateLimit                               20000

# Used to split Cassandra token-range into slices and migrate random slices one at a time
# 10K splits usually works for tables up to 100GB (uncompressed) with balanced token distribution
# For larger tables, test on 1% volume (using param coveragePercent) and increase the number-of-splits as needed
spark.numSplits                                   10000


# Below 'query' properties are set based on table schema
spark.query.origin                                comma-separated-partition-key,comma-separated-clustering-key,comma-separated-guardrail-columns
# Comma separated numeric data-type mapping (e.g. 'text' will map to '0') for all columns listed in "spark.query.origin"
spark.query.types                                 9,1,4
spark.guardrail.colSizeInKB                       10240

# ENABLE ONLY IF YOU WANT TO MIGRATE/VALIDATE ROWS BASED ON CQL FILTER
#spark.query.condition

# ENABLE ONLY IF YOU WANT TO FILTER BASED ON WRITE-TIME (values must be in microseconds)
#spark.origin.writeTimeStampFilter                 false
#spark.origin.minWriteTimeStampFilter              0
#spark.origin.maxWriteTimeStampFilter              4102444800000000

# ENABLE ONLY IF YOU WANT TO MIGRATE/VALIDATE SOME % OF ROWS (NOT 100%)
#spark.coveragePercent                             100

# ENABLE ONLY IF WANT LOG STATS MORE OR LESS FREQUENTLY THAN DEFAULT
#spark.printStatsAfter                             100000

# ENABLE ONLY IF YOU WANT TO USE READ AND/OR WRITE CONSISTENCY OTHER THAN LOCAL_QUORUM
#spark.consistency.read                            LOCAL_QUORUM
#spark.consistency.write                           LOCAL_QUORUM

# ENABLE ONLY IF YOU WANT TO REDUCE FETCH-SIZE TO AVOID FrameTooLongException
#spark.read.fetch.sizeInRows                       1000

# ONLY USE if SSL is enabled on origin Cassandra/DSE (e.g. Azure Cosmos Cassandra DB)
#spark.origin.ssl.enabled                          true

# ONLY USE if SSL clientAuth is enabled on origin Cassandra/DSE
#spark.origin.trustStore.path
#spark.origin.trustStore.password
#spark.origin.trustStore.type                     JKS
#spark.origin.keyStore.path
#spark.origin.keyStore.password
#spark.origin.enabledAlgorithms                   TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA
