spark.origin.isAstra                              false
spark.origin.host                                 localhost
spark.origin.username                             some-username
spark.origin.password                             some-secret-password
spark.origin.read.consistency.level               LOCAL_QUORUM
spark.origin.keyspaceTable                        test.a1
spark.origin.checkTableforColSize                 false
spark.origin.checkTableforColSize.cols            partition-key,clustering-key
spark.origin.checkTableforColSize.cols.types      9,1
spark.origin.FilterColumn                         test
spark.origin.FilterColumnIndex                    2
spark.origin.FilterColumnType                     6%16

spark.target.isAstra                              true
spark.target.scb                                  file:///aaa/bbb/secure-connect-enterprise.zip
spark.target.username                             client-id
spark.target.password                             client-secret
spark.target.read.consistency.level               LOCAL_QUORUM
spark.target.keyspaceTable                        test.a2
spark.target.autocorrect.missing                  false
spark.target.autocorrect.mismatch                 false
spark.target.custom.writeTime                     0

spark.maxRetries                                  10
spark.readRateLimit                               20000
spark.writeRateLimit                              20000
spark.splitSize                                   10000
spark.batchSize                                   5
spark.coveragePercent                             100
spark.printStatsAfter                             100000
spark.fieldGuardraillimitMB                       10

spark.query.origin                                partition-key,clustering-key,order-date,amount
spark.query.origin.partitionKey                   partition-key
spark.query.target                                partition-key,clustering-key,order-date,amount
spark.query.target.id                             partition-key,clustering-key
spark.query.types                                 9,1,4,3
spark.query.ttl.cols                              2,3
spark.query.writetime.cols                        2,3

spark.counterTable                                false
spark.counterTable.cql
spark.counterTable.cql.index                      0

spark.origin.writeTimeStampFilter                 false
spark.origin.minWriteTimeStampFilter              0
spark.origin.maxWriteTimeStampFilter              9223372036854775807

########################## ONLY USE if SSL clientAuth is enabled on origin Cassandra/DSE ###############################
#spark.origin.trustStore.path
#spark.origin.trustStore.password
#spark.origin.trustStore.type                     JKS
#spark.origin.keyStore.path
#spark.origin.keyStore.password
#spark.origin.enabledAlgorithms                   TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA

####################### ONLY USE if SSL clientAuth is enabled on target Cassandra/DSE #############################
#spark.target.trustStore.path
#spark.target.trustStore.password
#spark.target.trustStore.type                     JKS
#spark.target.keyStore.path
#spark.target.keyStore.password
#spark.target.enabledAlgorithms                   TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA

########################################################################################################################
# Following are the supported data types and their corresponding [Cassandra data-types]
# 0: String [ascii, text, varchar]
# 1: Integer [int, smallint]
# 2: Long [bigint, counter]
# 3: Double [double]
# 4: Instant [time, timestamp]
# 5: Map (separate type by %) [map] - Example: 5%1%0 for map<int, text>
# 6: List (separate type by %) [list] - Example: 6%0 for list<text>
# 7: ByteBuffer [blob]
# 8: Set (separate type by %) [set] - Example: 8%0 for set<text>
# 9: UUID [uuid, timeuuid]
# 10: Boolean [boolean]
# 11: TupleValue [tuple]
# 12: Float (float)
# 13: TinyInt [tinyint]
# 14: BigDecimal (decimal)
# 15: LocalDate (date)
# 16: UDT [any user-defined-type created using 'CREATE TYPE']
#
# "spark.query.ttl.cols" - Comma separated column indexes from "spark.query.origin" to used to find largest TTL.
# "spark.query.writetime.cols" - Comma separated column indexes from "spark.query.origin" to used to find largest writetime.
#  Note: The tool migrates TTL & Writetimes at row-level and not field-level. Migration will use the largest TTL & Writetimes value per row.
#
# "spark.target.custom.writeTime" - User specified writetime. When set, this static value will be used as writetime for target writes.
#
# Default value for "spark.origin.maxWriteTimeStampFilter" is "9223372036854775807" (max long value)
#
# Frozen has no impact on the mapping of Collections (Map/List/Set) - Example: 5%1%0 for frozen<map<int, text>>
#
########################################################################################################################
